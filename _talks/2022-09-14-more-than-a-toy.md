---
title: "Using Random Matrix Models to Predict How Real-World Neural Representations Generalize"
collection: talks
type: "Seminar in random matrix theory, machine learning and optimization"
permalink: /talks/2022-09-14-more-than-a-toy
venue: "McGill University"
date: 2022-09-14
location: "Montreal"
---

**Abstract**: How can we predict the generalization risk of overparametrized large-scale machine learning models? Even for simple but realistic regression problems, traditional theoretical analyses geared toward answering this question fail to capture some important qualitative behavior. Fortunately, the generalized cross validation (GCV) estimator can be used to accurately estimate the generalization risk. Based on the paper “More Than a Toy: Random Matrix Models Predict How Real-World Neural Representations Generalize” by Wei, Hu and Steinhardt, I will explain how the GCV predicts generalization risk while other common methods fail to do the same. If time permits, I will also state some implications of this result, notably on pretraining.

**Reference**: [https://arxiv.org/abs/2203.06176](https://arxiv.org/abs/2203.06176)
